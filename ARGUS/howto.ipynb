{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8757ade6ae3942f7b32cd17e73d210d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f43e1977fab4f6f99303421c8d3872d",
              "IPY_MODEL_6709c218e892431fb30c7cd5952e5d16",
              "IPY_MODEL_891311c21d994ae3810a7331153d86b5"
            ],
            "layout": "IPY_MODEL_d9be3430de2f4c5e8cbda898f915e653"
          }
        },
        "5f43e1977fab4f6f99303421c8d3872d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bc7c948386947f28bc0fa1f6b2bed36",
            "placeholder": "​",
            "style": "IPY_MODEL_a456e52bc6ce44d3be5eaa985e510f39",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6709c218e892431fb30c7cd5952e5d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf4c51cbf044849946d7032fde0d5b4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb00561fbf3449b5b3424e1368ea2bc3",
            "value": 3
          }
        },
        "891311c21d994ae3810a7331153d86b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a58758121d44d04b0643a15bf545388",
            "placeholder": "​",
            "style": "IPY_MODEL_a4490d656398488d9023a0b649b9b119",
            "value": " 3/3 [01:09&lt;00:00, 22.53s/it]"
          }
        },
        "d9be3430de2f4c5e8cbda898f915e653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc7c948386947f28bc0fa1f6b2bed36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a456e52bc6ce44d3be5eaa985e510f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bf4c51cbf044849946d7032fde0d5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb00561fbf3449b5b3424e1368ea2bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a58758121d44d04b0643a15bf545388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4490d656398488d9023a0b649b9b119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3349b39202c94d34b6ba221c17d9a95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd793f4c359640ff90b1caeeccb7709d",
              "IPY_MODEL_38a0e37d8feb40628126e2aae162275f",
              "IPY_MODEL_a92c4f0158f64be496de3f973561d8fe"
            ],
            "layout": "IPY_MODEL_2ab609dfa2dc45b091917f50d073d3b7"
          }
        },
        "cd793f4c359640ff90b1caeeccb7709d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a079bea47c047658ecbd5bc7fd97366",
            "placeholder": "​",
            "style": "IPY_MODEL_0c944acfae554b35834a3c59366454dc",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "38a0e37d8feb40628126e2aae162275f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22ec3a40f56f48e680b8e4ff10a2d8ee",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ce3b690f1b344f69d4b3b199b05efb2",
            "value": 3
          }
        },
        "a92c4f0158f64be496de3f973561d8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_840770312fe6471e800e9b1304e60811",
            "placeholder": "​",
            "style": "IPY_MODEL_3c569eb9ce244285962de632ffec44c3",
            "value": " 3/3 [01:09&lt;00:00, 22.65s/it]"
          }
        },
        "2ab609dfa2dc45b091917f50d073d3b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a079bea47c047658ecbd5bc7fd97366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c944acfae554b35834a3c59366454dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22ec3a40f56f48e680b8e4ff10a2d8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce3b690f1b344f69d4b3b199b05efb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "840770312fe6471e800e9b1304e60811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c569eb9ce244285962de632ffec44c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f94e746286464eb2a9eccbbe4e8f14f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_245e29c90891424abdd89db5f4bcd078",
              "IPY_MODEL_202fd04277a74465820958ecca712292",
              "IPY_MODEL_6f0ae7ef24fa463b862fd16511475fd4"
            ],
            "layout": "IPY_MODEL_ce333b64748b4c6e820e65f7458a07ea"
          }
        },
        "245e29c90891424abdd89db5f4bcd078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b24e8081d4d74c42a89ebfa0af95f1f5",
            "placeholder": "​",
            "style": "IPY_MODEL_4e5c09ce509042b4884777d4d4cae1c3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "202fd04277a74465820958ecca712292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a89031196604de68898ececd29c466e",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70538c6df14a45e4b0fe017d82cd6960",
            "value": 3
          }
        },
        "6f0ae7ef24fa463b862fd16511475fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e26bf733cf164fe68e653d5de31443ba",
            "placeholder": "​",
            "style": "IPY_MODEL_0b04813963c84234b5c481aa5feb8195",
            "value": " 3/3 [01:05&lt;00:00, 21.41s/it]"
          }
        },
        "ce333b64748b4c6e820e65f7458a07ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24e8081d4d74c42a89ebfa0af95f1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e5c09ce509042b4884777d4d4cae1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a89031196604de68898ececd29c466e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70538c6df14a45e4b0fe017d82cd6960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e26bf733cf164fe68e653d5de31443ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b04813963c84234b5c481aa5feb8195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/src.zip -d /content/\n",
        "# !unzip /content/data.zip -d /content/"
      ],
      "metadata": {
        "id": "tgWMQaCjVRWG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "22XXNWNvVQ_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QoNIxcDEVQ6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Dependencies**"
      ],
      "metadata": {
        "id": "kQWdlSHkCw14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PtaRksbiBrTY"
      },
      "outputs": [],
      "source": [
        "!pip install -qq -U \\\n",
        "  langchain \\\n",
        "  langgraph \\\n",
        "  chromadb \\\n",
        "  faiss-cpu \\\n",
        "  transformers \\\n",
        "  accelerate \\\n",
        "  bitsandbytes \\\n",
        "  sentence-transformers \\\n",
        "  pypdf \\\n",
        "  tavily-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import langgraph\n",
        "import chromadb\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "print(\"LangChain:\", langchain.__version__)\n",
        "# print(\"LangGraph:\", langgraph.__version__)\n",
        "print(\"Chroma:\", chromadb.__version__)\n",
        "print(\"Transformers:\", transformers.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8_9fcuJByXF",
        "outputId": "e571d453-92f4-4a3e-aa84-5fa3a2d063bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain: 1.2.0\n",
            "Chroma: 1.4.0\n",
            "Transformers: 4.57.3\n",
            "CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.llm.model import load_llm\n",
        "import torch\n",
        "\n",
        "tokenizer, model = load_llm()\n",
        "\n",
        "prompt = \"Explain what retrieval augmented generation is in one sentence.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "8757ade6ae3942f7b32cd17e73d210d3",
            "5f43e1977fab4f6f99303421c8d3872d",
            "6709c218e892431fb30c7cd5952e5d16",
            "891311c21d994ae3810a7331153d86b5",
            "d9be3430de2f4c5e8cbda898f915e653",
            "6bc7c948386947f28bc0fa1f6b2bed36",
            "a456e52bc6ce44d3be5eaa985e510f39",
            "1bf4c51cbf044849946d7032fde0d5b4",
            "bb00561fbf3449b5b3424e1368ea2bc3",
            "5a58758121d44d04b0643a15bf545388",
            "a4490d656398488d9023a0b649b9b119"
          ]
        },
        "id": "6TaVc7H0D0Xc",
        "outputId": "e482e75f-a6c6-41f3-9767-b78fc13e2e1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8757ade6ae3942f7b32cd17e73d210d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain what retrieval augmented generation is in one sentence. Retrieval augmented generation is a method that combines the strengths of retrieval models and generation models to produce more accurate and contextually relevant responses.\n",
            "\n",
            "Retrieval augmented generation (RAG) is a cutting-edge approach that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMsuqv4xJTIM",
        "outputId": "2f358f24-fb7d-4171-bb4a-717c868d3b56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.2.5)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.59)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-text-splitters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXK9m9o5KCmG",
        "outputId": "810ea88a-34df-4d8c-f831-598dc92b45da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-text-splitters) (1.2.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.59)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.12.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain-text-splitters) (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.ingestion.ingest import load_papers, chunk_documents\n",
        "from src.ingestion.vectorstore import build_vectorstore\n",
        "\n",
        "docs = load_papers()\n",
        "print(f\"Loaded pages: {len(docs)}\")\n",
        "\n",
        "chunks = chunk_documents(docs)\n",
        "print(f\"Created chunks: {len(chunks)}\")\n",
        "\n",
        "vectordb = build_vectorstore(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAIY7ceiD7Yq",
        "outputId": "c5e37bef-8d4c-47fc-faf9-b554d71fbfdc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pages: 119\n",
            "Created chunks: 973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/src/ingestion/vectorstore.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/content/src/ingestion/vectorstore.py:15: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectordb.persist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.ingestion.ingest import load_papers, chunk_documents\n",
        "from src.ingestion.vectorstore import build_vectorstore\n",
        "from src.rag.baseline import BaselineRAG\n",
        "\n",
        "# Load vector store\n",
        "docs = load_papers()\n",
        "chunks = chunk_documents(docs)\n",
        "vectordb = build_vectorstore(chunks)\n",
        "\n",
        "# Initialize baseline RAG\n",
        "rag = BaselineRAG(vectordb)\n",
        "\n",
        "query = \"How does knowledge distillation improve small object detection performance in YOLO-based models?\"\n",
        "\n",
        "answer = rag.answer(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3349b39202c94d34b6ba221c17d9a95c",
            "cd793f4c359640ff90b1caeeccb7709d",
            "38a0e37d8feb40628126e2aae162275f",
            "a92c4f0158f64be496de3f973561d8fe",
            "2ab609dfa2dc45b091917f50d073d3b7",
            "4a079bea47c047658ecbd5bc7fd97366",
            "0c944acfae554b35834a3c59366454dc",
            "22ec3a40f56f48e680b8e4ff10a2d8ee",
            "7ce3b690f1b344f69d4b3b199b05efb2",
            "840770312fe6471e800e9b1304e60811",
            "3c569eb9ce244285962de632ffec44c3"
          ]
        },
        "id": "Xtv1Ea0kIIEJ",
        "outputId": "ee622419-04d0-4739-e690-8acaa1045e70"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3349b39202c94d34b6ba221c17d9a95c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a research assistant.\n",
            "\n",
            "Use the provided context to answer the question.\n",
            "If the answer is not explicitly stated, try your best to infer it.\n",
            "\n",
            "Context:\n",
            "Source: paper_2.pdf\n",
            "[4] G. Chen, W. Choi, X. Yu, T. Han, and M. Chandraker, “Learning efﬁ-\n",
            "cient object detection models with knowledge distillation,” inProc. Adv.\n",
            "Neural Inf. Process. Syst., 2017, pp. 742–751.\n",
            "[5] Z. Xing, X. Chen, and F. Pang, “DD-YOLO: An object detection method\n",
            "combining knowledge distillation and differentiable architecture search,”\n",
            "IET Comput. Vis., vol. 16, pp. 418–430, 2022.\n",
            "[6] Z. Li et al., “A compression pipeline for one-stage object detection\n",
            "model,” J. Real-Time Image Process., vol. 18, pp. 1949–1962, 2021.\n",
            "[7] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural\n",
            "network,” 2015,arXiv:1503.02531.\n",
            "\n",
            "Source: paper_2.pdf\n",
            "[4] G. Chen, W. Choi, X. Yu, T. Han, and M. Chandraker, “Learning efﬁ-\n",
            "cient object detection models with knowledge distillation,” inProc. Adv.\n",
            "Neural Inf. Process. Syst., 2017, pp. 742–751.\n",
            "[5] Z. Xing, X. Chen, and F. Pang, “DD-YOLO: An object detection method\n",
            "combining knowledge distillation and differentiable architecture search,”\n",
            "IET Comput. Vis., vol. 16, pp. 418–430, 2022.\n",
            "[6] Z. Li et al., “A compression pipeline for one-stage object detection\n",
            "model,” J. Real-Time Image Process., vol. 18, pp. 1949–1962, 2021.\n",
            "[7] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural\n",
            "network,” 2015,arXiv:1503.02531.\n",
            "\n",
            "Source: paper_2.pdf\n",
            "[4] G. Chen, W. Choi, X. Yu, T. Han, and M. Chandraker, “Learning efﬁ-\n",
            "cient object detection models with knowledge distillation,” inProc. Adv.\n",
            "Neural Inf. Process. Syst., 2017, pp. 742–751.\n",
            "[5] Z. Xing, X. Chen, and F. Pang, “DD-YOLO: An object detection method\n",
            "combining knowledge distillation and differentiable architecture search,”\n",
            "IET Comput. Vis., vol. 16, pp. 418–430, 2022.\n",
            "[6] Z. Li et al., “A compression pipeline for one-stage object detection\n",
            "model,” J. Real-Time Image Process., vol. 18, pp. 1949–1962, 2021.\n",
            "[7] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural\n",
            "network,” 2015,arXiv:1503.02531.\n",
            "\n",
            "Source: paper_2.pdf\n",
            "[4] G. Chen, W. Choi, X. Yu, T. Han, and M. Chandraker, “Learning efﬁ-\n",
            "cient object detection models with knowledge distillation,” inProc. Adv.\n",
            "Neural Inf. Process. Syst., 2017, pp. 742–751.\n",
            "[5] Z. Xing, X. Chen, and F. Pang, “DD-YOLO: An object detection method\n",
            "combining knowledge distillation and differentiable architecture search,”\n",
            "IET Comput. Vis., vol. 16, pp. 418–430, 2022.\n",
            "[6] Z. Li et al., “A compression pipeline for one-stage object detection\n",
            "model,” J. Real-Time Image Process., vol. 18, pp. 1949–1962, 2021.\n",
            "[7] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural\n",
            "network,” 2015,arXiv:1503.02531.\n",
            "\n",
            "Question:\n",
            "How does knowledge distillation improve small object detection performance in YOLO-based models?\n",
            "\n",
            "Answer:\n",
            "Knowledge distillation is a technique used to transfer knowledge from a large and complex model (teacher model) to a smaller and simpler model (student model). In the context of YOLO-based models, knowledge distillation can improve small object detection performance by having the student model learn from the predictions of the teacher model instead of directly from the raw data. This can help the student model learn more accurate and robust object detections, especially for small objects that may be difficult for the student model to detect on its own. The teacher model, which is typically larger and more complex, is able to capture more context and subtle features in the data, which can then be distilled and transferred to the student model. This can lead to improved detection performance for small objects, as well as more efficient and computationally lightweight models. (Sources: [4], [5], [7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = [\"Which distillation loss is most effective for small object detection according to the papers?\",\n",
        "\"Do feature-level or response-level distillation methods perform better across datasets?\",\n",
        "\"What teacher-student architectures consistently outperform baselines?\"]\n",
        "for q in query:\n",
        "    answer = rag.answer(q)\n",
        "    print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FXug4ETMEDY",
        "outputId": "d697d2d4-d23d-421c-868d-792ab9a3e99b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a research assistant.\n",
            "\n",
            "Use the provided context to answer the question.\n",
            "If the answer is not explicitly stated, try your best to infer it.\n",
            "\n",
            "Context:\n",
            "Source: paper_10.pdf\n",
            "loss as follows:\n",
            "L= Loriginal + Lfocal + Lglobal (13)\n",
            "where Loriginal is the original loss for detectors.\n",
            "The distillation loss is calculated just on feature maps,\n",
            "which can be obtained from the neck of the detectors. So it\n",
            "can be easily applied to different detectors.\n",
            "4. Experiments\n",
            "4.1. Dataset\n",
            "We evaluate our knowledge distillation method on\n",
            "COCO dataset [21], which contains 80 object classes. We\n",
            "use the 120k train images for training and 5k val images\n",
            "for testing for all the experiments. The performances of\n",
            "different detectors are evaluated in Average Precision and\n",
            "Average Recall.\n",
            "Method mAP AP S APM APL\n",
            "RetinaNet-Res101(T) 38.9 21.0 42.8 52.4\n",
            "RetinaNet-Res50(S) 37.4 20.6 40.7 49.7\n",
            "\n",
            "Source: paper_10.pdf\n",
            "loss as follows:\n",
            "L= Loriginal + Lfocal + Lglobal (13)\n",
            "where Loriginal is the original loss for detectors.\n",
            "The distillation loss is calculated just on feature maps,\n",
            "which can be obtained from the neck of the detectors. So it\n",
            "can be easily applied to different detectors.\n",
            "4. Experiments\n",
            "4.1. Dataset\n",
            "We evaluate our knowledge distillation method on\n",
            "COCO dataset [21], which contains 80 object classes. We\n",
            "use the 120k train images for training and 5k val images\n",
            "for testing for all the experiments. The performances of\n",
            "different detectors are evaluated in Average Precision and\n",
            "Average Recall.\n",
            "Method mAP AP S APM APL\n",
            "RetinaNet-Res101(T) 38.9 21.0 42.8 52.4\n",
            "RetinaNet-Res50(S) 37.4 20.6 40.7 49.7\n",
            "\n",
            "Source: paper_10.pdf\n",
            "loss as follows:\n",
            "L= Loriginal + Lfocal + Lglobal (13)\n",
            "where Loriginal is the original loss for detectors.\n",
            "The distillation loss is calculated just on feature maps,\n",
            "which can be obtained from the neck of the detectors. So it\n",
            "can be easily applied to different detectors.\n",
            "4. Experiments\n",
            "4.1. Dataset\n",
            "We evaluate our knowledge distillation method on\n",
            "COCO dataset [21], which contains 80 object classes. We\n",
            "use the 120k train images for training and 5k val images\n",
            "for testing for all the experiments. The performances of\n",
            "different detectors are evaluated in Average Precision and\n",
            "Average Recall.\n",
            "Method mAP AP S APM APL\n",
            "RetinaNet-Res101(T) 38.9 21.0 42.8 52.4\n",
            "RetinaNet-Res50(S) 37.4 20.6 40.7 49.7\n",
            "\n",
            "Source: paper_10.pdf\n",
            "loss as follows:\n",
            "L= Loriginal + Lfocal + Lglobal (13)\n",
            "where Loriginal is the original loss for detectors.\n",
            "The distillation loss is calculated just on feature maps,\n",
            "which can be obtained from the neck of the detectors. So it\n",
            "can be easily applied to different detectors.\n",
            "4. Experiments\n",
            "4.1. Dataset\n",
            "We evaluate our knowledge distillation method on\n",
            "COCO dataset [21], which contains 80 object classes. We\n",
            "use the 120k train images for training and 5k val images\n",
            "for testing for all the experiments. The performances of\n",
            "different detectors are evaluated in Average Precision and\n",
            "Average Recall.\n",
            "Method mAP AP S APM APL\n",
            "RetinaNet-Res101(T) 38.9 21.0 42.8 52.4\n",
            "RetinaNet-Res50(S) 37.4 20.6 40.7 49.7\n",
            "\n",
            "Question:\n",
            "Which distillation loss is most effective for small object detection according to the papers?\n",
            "\n",
            "Answer:\n",
            "The context does not provide enough information to determine which distillation loss is most effective for small object detection according to the papers. The provided context only mentions the use of knowledge distillation with the distillation loss calculated on feature maps, but it does not specify which of the provided distillation losses (Lfocal or Lglobal) is most effective for small object detection. Additionally, the context only evaluates the performance of the knowledge distillation method on the COCO dataset, but it does not provide enough information to determine which distillation loss is most effective specifically for small object detection on this dataset. Further research and analysis would be needed to answer this question definitively.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a research assistant.\n",
            "\n",
            "Use the provided context to answer the question.\n",
            "If the answer is not explicitly stated, try your best to infer it.\n",
            "\n",
            "Context:\n",
            "Source: paper_6.pdf\n",
            "Distillation w/o FM-NMSVOCOCO61.1 (-3.1) 61.8 (-2.1)\n",
            "Distillation w/o Obj-scalingVOCOCO65.8 (+1.2) 64.9 (+1.0)\n",
            "Distillation full VOCOCO66.9 (+2.7) 66.1 (2.1)\n",
            "Table 3: Comparison of performance for distillation with\n",
            "different strategies on Pascal VOC 2007. The results are\n",
            "shown for two teacher network and for two set of labeled\n",
            "training data (Pascal VOC and combination of Pascal VOC\n",
            "and COCO).\n",
            "feature map merging on the base architecture. The results\n",
            "for different layer combinations are shown in Table 1. It can\n",
            "be observed that the accuracy increases as the feature maps\n",
            "from more layers are merged together. Another important\n",
            "inference that we can draw from these results is that merg-\n",
            "\n",
            "Source: paper_6.pdf\n",
            "Distillation w/o FM-NMSVOCOCO61.1 (-3.1) 61.8 (-2.1)\n",
            "Distillation w/o Obj-scalingVOCOCO65.8 (+1.2) 64.9 (+1.0)\n",
            "Distillation full VOCOCO66.9 (+2.7) 66.1 (2.1)\n",
            "Table 3: Comparison of performance for distillation with\n",
            "different strategies on Pascal VOC 2007. The results are\n",
            "shown for two teacher network and for two set of labeled\n",
            "training data (Pascal VOC and combination of Pascal VOC\n",
            "and COCO).\n",
            "feature map merging on the base architecture. The results\n",
            "for different layer combinations are shown in Table 1. It can\n",
            "be observed that the accuracy increases as the feature maps\n",
            "from more layers are merged together. Another important\n",
            "inference that we can draw from these results is that merg-\n",
            "\n",
            "Source: paper_6.pdf\n",
            "Distillation w/o FM-NMSVOCOCO61.1 (-3.1) 61.8 (-2.1)\n",
            "Distillation w/o Obj-scalingVOCOCO65.8 (+1.2) 64.9 (+1.0)\n",
            "Distillation full VOCOCO66.9 (+2.7) 66.1 (2.1)\n",
            "Table 3: Comparison of performance for distillation with\n",
            "different strategies on Pascal VOC 2007. The results are\n",
            "shown for two teacher network and for two set of labeled\n",
            "training data (Pascal VOC and combination of Pascal VOC\n",
            "and COCO).\n",
            "feature map merging on the base architecture. The results\n",
            "for different layer combinations are shown in Table 1. It can\n",
            "be observed that the accuracy increases as the feature maps\n",
            "from more layers are merged together. Another important\n",
            "inference that we can draw from these results is that merg-\n",
            "\n",
            "Source: paper_6.pdf\n",
            "Distillation w/o FM-NMSVOCOCO61.1 (-3.1) 61.8 (-2.1)\n",
            "Distillation w/o Obj-scalingVOCOCO65.8 (+1.2) 64.9 (+1.0)\n",
            "Distillation full VOCOCO66.9 (+2.7) 66.1 (2.1)\n",
            "Table 3: Comparison of performance for distillation with\n",
            "different strategies on Pascal VOC 2007. The results are\n",
            "shown for two teacher network and for two set of labeled\n",
            "training data (Pascal VOC and combination of Pascal VOC\n",
            "and COCO).\n",
            "feature map merging on the base architecture. The results\n",
            "for different layer combinations are shown in Table 1. It can\n",
            "be observed that the accuracy increases as the feature maps\n",
            "from more layers are merged together. Another important\n",
            "inference that we can draw from these results is that merg-\n",
            "\n",
            "Question:\n",
            "Do feature-level or response-level distillation methods perform better across datasets?\n",
            "\n",
            "Answer:\n",
            "The context provided does not directly answer the question as it only compares the performance of different distillation methods on Pascal VOC 2007 using feature map merging on the base architecture. However, we can infer from the results that merging feature maps from more layers generally leads to higher accuracy. This suggests that feature-level distillation may perform better as it allows for the transfer of more detailed information from the teacher network to the student network at the feature level. However, it's important to note that this is not a definitive answer as the context only provides results on one dataset and there may be other factors that come into play when comparing feature-level and response-level distillation methods across different datasets.\n",
            "You are a research assistant.\n",
            "\n",
            "Use the provided context to answer the question.\n",
            "If the answer is not explicitly stated, try your best to infer it.\n",
            "\n",
            "Context:\n",
            "Source: paper_8.pdf\n",
            "schedule, after joining CoLAD for another 1×, outper-\n",
            "forms the one independently trained for 2×schedule. Con-\n",
            "cretely, CoLAD improves the teachers PAA-R50 from41.6\n",
            "to 42.6AP(+1.0) (1st vs. 5th row), and PAA-R101 from43.5\n",
            "to 44.1AP(+0.6) (2nd vs. 4th row). Finally, the experiments\n",
            "above support our hypothesis that the dynamic switching\n",
            "mechanism of CoLAD reduces the risk of local minima\n",
            "trapping, and that is why it outperforms the baseline PAA.\n",
            "4.2.3 Impact of Teacher-Student’s relative model sizes\n",
            "To understand how the relative gap between the model sizes\n",
            "can affect the student’s performance, we compare the results\n",
            "of two model pairs, including (PAA-R18, PAA-R50) and\n",
            "\n",
            "Source: paper_8.pdf\n",
            "schedule, after joining CoLAD for another 1×, outper-\n",
            "forms the one independently trained for 2×schedule. Con-\n",
            "cretely, CoLAD improves the teachers PAA-R50 from41.6\n",
            "to 42.6AP(+1.0) (1st vs. 5th row), and PAA-R101 from43.5\n",
            "to 44.1AP(+0.6) (2nd vs. 4th row). Finally, the experiments\n",
            "above support our hypothesis that the dynamic switching\n",
            "mechanism of CoLAD reduces the risk of local minima\n",
            "trapping, and that is why it outperforms the baseline PAA.\n",
            "4.2.3 Impact of Teacher-Student’s relative model sizes\n",
            "To understand how the relative gap between the model sizes\n",
            "can affect the student’s performance, we compare the results\n",
            "of two model pairs, including (PAA-R18, PAA-R50) and\n",
            "\n",
            "Source: paper_8.pdf\n",
            "schedule, after joining CoLAD for another 1×, outper-\n",
            "forms the one independently trained for 2×schedule. Con-\n",
            "cretely, CoLAD improves the teachers PAA-R50 from41.6\n",
            "to 42.6AP(+1.0) (1st vs. 5th row), and PAA-R101 from43.5\n",
            "to 44.1AP(+0.6) (2nd vs. 4th row). Finally, the experiments\n",
            "above support our hypothesis that the dynamic switching\n",
            "mechanism of CoLAD reduces the risk of local minima\n",
            "trapping, and that is why it outperforms the baseline PAA.\n",
            "4.2.3 Impact of Teacher-Student’s relative model sizes\n",
            "To understand how the relative gap between the model sizes\n",
            "can affect the student’s performance, we compare the results\n",
            "of two model pairs, including (PAA-R18, PAA-R50) and\n",
            "\n",
            "Source: paper_8.pdf\n",
            "schedule, after joining CoLAD for another 1×, outper-\n",
            "forms the one independently trained for 2×schedule. Con-\n",
            "cretely, CoLAD improves the teachers PAA-R50 from41.6\n",
            "to 42.6AP(+1.0) (1st vs. 5th row), and PAA-R101 from43.5\n",
            "to 44.1AP(+0.6) (2nd vs. 4th row). Finally, the experiments\n",
            "above support our hypothesis that the dynamic switching\n",
            "mechanism of CoLAD reduces the risk of local minima\n",
            "trapping, and that is why it outperforms the baseline PAA.\n",
            "4.2.3 Impact of Teacher-Student’s relative model sizes\n",
            "To understand how the relative gap between the model sizes\n",
            "can affect the student’s performance, we compare the results\n",
            "of two model pairs, including (PAA-R18, PAA-R50) and\n",
            "\n",
            "Question:\n",
            "What teacher-student architectures consistently outperform baselines?\n",
            "\n",
            "Answer:\n",
            "The paper suggests that the teacher-student architecture using CoLAD (Progressive Growing of GANs) consistently outperforms the baseline PAA (Progressive Growing of GANs without CoLAD) based on the experiments conducted. The improvements in PAA-R50 and PAA-R101 are significant, with an increase of 1.0 and 0.6 AP, respectively. The dynamic switching mechanism of CoLAD is hypothesized to reduce the risk of local minima trapping, which is why it outperforms the baseline PAA.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.ingestion.ingest import load_papers, chunk_documents\n",
        "from src.ingestion.vectorstore import build_vectorstore\n",
        "from src.agents.relevance_grader import RelevanceGrader\n",
        "\n",
        "docs = load_papers()\n",
        "chunks = chunk_documents(docs)\n",
        "vectordb = build_vectorstore(chunks)\n",
        "\n",
        "query = \"How does feature-level distillation improve small object detection?\"\n",
        "retrieved = vectordb.similarity_search(query, k=3)\n",
        "\n",
        "grader = RelevanceGrader()\n",
        "\n",
        "for doc in retrieved:\n",
        "    result = grader.grade(query, doc)\n",
        "    print(result)\n",
        "    print(doc.page_content[:200])\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434,
          "referenced_widgets": [
            "f94e746286464eb2a9eccbbe4e8f14f2",
            "245e29c90891424abdd89db5f4bcd078",
            "202fd04277a74465820958ecca712292",
            "6f0ae7ef24fa463b862fd16511475fd4",
            "ce333b64748b4c6e820e65f7458a07ea",
            "b24e8081d4d74c42a89ebfa0af95f1f5",
            "4e5c09ce509042b4884777d4d4cae1c3",
            "1a89031196604de68898ececd29c466e",
            "70538c6df14a45e4b0fe017d82cd6960",
            "e26bf733cf164fe68e653d5de31443ba",
            "0b04813963c84234b5c481aa5feb8195"
          ]
        },
        "id": "MGIX6cRwNrfN",
        "outputId": "6b2861b6-68f7-41c0-ee22-6dd65961a4e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f94e746286464eb2a9eccbbe4e8f14f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'relevant': 'yes', 'reason': 'The document chunk discusses the use of feature-level distillation in object detection, which is specifically mentioned in the question.'}\n",
            "to the web version of this article.)\n",
            "the feature-based distillation, which utilizes the semantic information\n",
            "of feature. Unlike the response-based distillation only in the output\n",
            "layer, feature-based \n",
            "----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'relevant': 'yes', 'reason': 'The document chunk discusses the use of feature-level distillation in object detection, which is specifically mentioned in the question.'}\n",
            "to the web version of this article.)\n",
            "the feature-based distillation, which utilizes the semantic information\n",
            "of feature. Unlike the response-based distillation only in the output\n",
            "layer, feature-based \n",
            "----\n",
            "{'relevant': 'yes', 'reason': 'The document chunk discusses the use of feature-level distillation in object detection, which is specifically mentioned in the question.'}\n",
            "to the web version of this article.)\n",
            "the feature-based distillation, which utilizes the semantic information\n",
            "of feature. Unlike the response-based distillation only in the output\n",
            "layer, feature-based \n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip /content/data -r /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY6RC4AcO_Cw",
        "outputId": "1df0c917-a846-4755-fdf0-e3dc1adafb26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: content/.config/ (stored 0%)\n",
            "  adding: content/.config/config_sentinel (stored 0%)\n",
            "  adding: content/.config/active_config (stored 0%)\n",
            "  adding: content/.config/default_configs.db (deflated 98%)\n",
            "  adding: content/.config/configurations/ (stored 0%)\n",
            "  adding: content/.config/configurations/config_default (deflated 15%)\n",
            "  adding: content/.config/gce (stored 0%)\n",
            "  adding: content/.config/.last_survey_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/.last_opt_in_prompt.yaml (stored 0%)\n",
            "  adding: content/.config/logs/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.12.09/ (stored 0%)\n",
            "  adding: content/.config/logs/2025.12.09/14.41.18.717681.log (deflated 58%)\n",
            "  adding: content/.config/logs/2025.12.09/14.41.42.675750.log (deflated 57%)\n",
            "  adding: content/.config/logs/2025.12.09/14.40.47.605300.log (deflated 92%)\n",
            "  adding: content/.config/logs/2025.12.09/14.41.33.792924.log (deflated 58%)\n",
            "  adding: content/.config/logs/2025.12.09/14.41.27.893750.log (deflated 86%)\n",
            "  adding: content/.config/logs/2025.12.09/14.41.43.412452.log (deflated 56%)\n",
            "  adding: content/.config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db (deflated 97%)\n",
            "  adding: content/.config/.last_update_check.json (deflated 22%)\n",
            "  adding: content/src/ (stored 0%)\n",
            "  adding: content/src/utils/ (stored 0%)\n",
            "  adding: content/src/utils/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/src/utils/prompts.py (deflated 28%)\n",
            "  adding: content/src/utils/__pycache__/ (stored 0%)\n",
            "  adding: content/src/utils/__pycache__/prompts.cpython-312.pyc (deflated 22%)\n",
            "  adding: content/src/llm/ (stored 0%)\n",
            "  adding: content/src/llm/model.py (deflated 55%)\n",
            "  adding: content/src/llm/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/src/llm/__pycache__/ (stored 0%)\n",
            "  adding: content/src/llm/__pycache__/model.cpython-312.pyc (deflated 35%)\n",
            "  adding: content/src/graph/ (stored 0%)\n",
            "  adding: content/src/graph/state.py (deflated 36%)\n",
            "  adding: content/src/graph/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/src/graph/nodes.py (deflated 66%)\n",
            "  adding: content/src/graph/__pycache__/ (stored 0%)\n",
            "  adding: content/src/graph/__pycache__/state.cpython-312.pyc (deflated 28%)\n",
            "  adding: content/src/graph/__pycache__/workflow.cpython-312.pyc (deflated 39%)\n",
            "  adding: content/src/graph/__pycache__/nodes.cpython-312.pyc (deflated 39%)\n",
            "  adding: content/src/graph/workflow.py (deflated 59%)\n",
            "  adding: content/src/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/src/ingestion/ (stored 0%)\n",
            "  adding: content/src/ingestion/ingest.py (deflated 57%)\n",
            "  adding: content/src/ingestion/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/src/ingestion/vectorstore.py (deflated 50%)\n",
            "  adding: content/src/ingestion/__pycache__/ (stored 0%)\n",
            "  adding: content/src/ingestion/__pycache__/ingest.cpython-312.pyc (deflated 35%)\n",
            "  adding: content/src/ingestion/__pycache__/vectorstore.cpython-312.pyc (deflated 32%)\n",
            "  adding: content/src/rag/ (stored 0%)\n",
            "  adding: content/src/rag/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/src/rag/graded_rag.py (deflated 55%)\n",
            "  adding: content/src/rag/__pycache__/ (stored 0%)\n",
            "  adding: content/src/rag/__pycache__/baseline.cpython-312.pyc (deflated 41%)\n",
            "  adding: content/src/rag/baseline.py (deflated 57%)\n",
            "  adding: content/src/agents/ (stored 0%)\n",
            "  adding: content/src/agents/query_rewriter.py (deflated 51%)\n",
            "  adding: content/src/agents/relevance_grader.py (deflated 57%)\n",
            "  adding: content/src/agents/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/src/agents/__pycache__/ (stored 0%)\n",
            "  adding: content/src/agents/__pycache__/answer_generator.cpython-312.pyc (deflated 39%)\n",
            "  adding: content/src/agents/__pycache__/relevance_grader.cpython-312.pyc (deflated 39%)\n",
            "  adding: content/src/agents/__pycache__/query_rewriter.cpython-312.pyc (deflated 39%)\n",
            "  adding: content/src/agents/answer_generator.py (deflated 53%)\n",
            "  adding: content/data.zip (stored 0%)\n",
            "  adding: content/data/ (stored 0%)\n",
            "  adding: content/data/raw/ (stored 0%)\n",
            "  adding: content/data/raw/paper_6.pdf (deflated 4%)\n",
            "  adding: content/data/raw/paper_3.pdf (deflated 11%)\n",
            "  adding: content/data/raw/paper_7.pdf (deflated 3%)\n",
            "  adding: content/data/raw/paper_9.pdf (deflated 4%)\n",
            "  adding: content/data/raw/paper_8.pdf (deflated 11%)\n",
            "  adding: content/data/raw/paper_10.pdf (deflated 5%)\n",
            "  adding: content/data/raw/paper_2.pdf (deflated 19%)\n",
            "  adding: content/data/raw/paper_5.pdf (deflated 5%)\n",
            "  adding: content/data/raw/paper_4.pdf (deflated 4%)\n",
            "  adding: content/data/raw/paper_1.pdf (deflated 6%)\n",
            "  adding: content/data/processed/ (stored 0%)\n",
            "  adding: content/data/processed/chroma/ (stored 0%)\n",
            "  adding: content/data/processed/chroma/e786acc8-6914-44c2-8128-d0ecf1757f63/ (stored 0%)\n",
            "  adding: content/data/processed/chroma/e786acc8-6914-44c2-8128-d0ecf1757f63/length.bin (deflated 92%)\n",
            "  adding: content/data/processed/chroma/e786acc8-6914-44c2-8128-d0ecf1757f63/data_level0.bin (deflated 10%)\n",
            "  adding: content/data/processed/chroma/e786acc8-6914-44c2-8128-d0ecf1757f63/link_lists.bin (deflated 76%)\n",
            "  adding: content/data/processed/chroma/e786acc8-6914-44c2-8128-d0ecf1757f63/header.bin (deflated 56%)\n",
            "  adding: content/data/processed/chroma/e786acc8-6914-44c2-8128-d0ecf1757f63/index_metadata.pickle (deflated 44%)\n",
            "  adding: content/data/processed/chroma/chroma.sqlite3 (deflated 75%)\n",
            "  adding: content/data/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/sample_data/ (stored 0%)\n",
            "  adding: content/sample_data/anscombe.json (deflated 83%)\n",
            "  adding: content/sample_data/README.md (deflated 39%)\n",
            "  adding: content/sample_data/mnist_train_small.csv (deflated 88%)\n",
            "  adding: content/sample_data/california_housing_test.csv (deflated 76%)\n",
            "  adding: content/sample_data/california_housing_train.csv (deflated 79%)\n",
            "  adding: content/sample_data/mnist_test.csv (deflated 88%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.graph.workflow import build_graph\n",
        "\n",
        "graph = build_graph(vectordb)\n",
        "\n",
        "initial_state = {\n",
        "    \"query\": \"How does knowledge distillation help small object detection?\",\n",
        "    \"documents\": [],\n",
        "    \"relevant_docs\": [],\n",
        "    \"retry_count\": 0,\n",
        "}\n",
        "\n",
        "final_state = graph.invoke(initial_state)\n",
        "\n",
        "print(\"Final Query:\", final_state[\"query\"])\n",
        "print(\"Relevant chunks:\", len(final_state[\"relevant_docs\"]))"
      ],
      "metadata": {
        "id": "aX9ad2c9dhNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3290c61d-b23c-4c86-adc4-58d865f6eacd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Query: \"What is the role of knowledge distillation in enhancing small object detection performance?\"\n",
            "Relevant chunks: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.agents.answer_generator import AnswerGenerator\n",
        "from src.ingestion.ingest import load_papers, chunk_documents\n",
        "from src.ingestion.vectorstore import build_vectorstore\n",
        "\n",
        "docs = load_papers()\n",
        "chunks = chunk_documents(docs)\n",
        "vectordb = build_vectorstore(chunks)\n",
        "query = \"How does knowledge distillation help small object detection?\"\n",
        "\n",
        "retrieved = vectordb.similarity_search(query, k=5)\n",
        "\n",
        "generator = AnswerGenerator()\n",
        "\n",
        "answer = generator.generate(\n",
        "    question=query,\n",
        "    documents=retrieved\n",
        ")\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVuE3o7PaaVf",
        "outputId": "61bde496-923e-4316-c3d5-4a9de5d9ae97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Knowledge distillation helps small object detection by transferring useful structure and semantic information from a larger, more complex \"teacher\" model to a smaller, simpler \"student\" model. This is done to improve the accuracy of the student model, which in this context is a detection model. The information is transferred through a combination of structure loss (Lsize) and offset loss (Loff), along with the original detection loss (Lk). The overall training objective for the detection model includes these losses, with tunable parameters to balance their contributions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from src.graph.workflow import build_graph\n",
        "# from src.ingestion.ingest import load_papers, chunk_documents\n",
        "# from src.ingestion.vectorstore import build_vectorstore\n",
        "\n",
        "# docs = load_papers()\n",
        "# print(f\"Loaded pages: {len(docs)}\")\n",
        "\n",
        "# chunks = chunk_documents(docs)\n",
        "# print(f\"Created chunks: {len(chunks)}\")\n",
        "\n",
        "# vectordb = build_vectorstore(chunks)\n",
        "# graph = build_graph(vectordb)\n",
        "# initial_state = {\n",
        "#     \"query\": \"What is Closed-loop unified knowledge distillation for dense object detection?\",\n",
        "#     \"retry_count\": 0\n",
        "# }\n",
        "\n",
        "# final_state = graph.invoke(initial_state)\n",
        "\n",
        "# print(\"Final Query:\", final_state[\"query\"])\n",
        "# print(\"Retries:\", final_state[\"retry_count\"])\n",
        "# print(\"Relevant Chunks:\", len(final_state[\"relevant_docs\"]))\n",
        "# print(\"\\nANSWER:\\n\")\n",
        "# print(final_state[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "x8c5CjRZl4fG",
        "outputId": "df60980e-5d57-4958-b097-3b7998932eb9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pages: 119\n",
            "Created chunks: 973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Query: What is Closed-loop unified knowledge distillation for dense object detection?\n",
            "Retries: 0\n",
            "Relevant Chunks: 6\n",
            "\n",
            "ANSWER:\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'answer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2324901418.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Relevant Chunks:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"relevant_docs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nANSWER:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'answer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aC6QutqOmKx0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}